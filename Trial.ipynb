{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from dataloader import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../test_data/normal/'\n",
    "num_workers = 1\n",
    "batch_size=1\n",
    "patchsize = (64,64)\n",
    "margin = (80,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = cevae(path,patchsize=patchsize,margin=margin)\n",
    "trainLoader = DataLoader(train_data,batch_size=batch_size,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIter = iter(trainLoader)\n",
    "test = trainIter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(trainLoader):\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e5c87da91cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "print(trainLoader.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bbox(image, margin, patchsize):\n",
    "    \"\"\"Generate a random tlhw with configuration.\n",
    "        Args:\n",
    "        config: Config should have configuration including IMG_SHAPES, VERTICAL_MARGIN, HEIGHT, HORIZONTAL_MARGIN, WIDTH.\n",
    "        Returns:\n",
    "        tuple: (top, left, height, width)\n",
    "    \"\"\"\n",
    "    img_height = image.shape[0]\n",
    "    img_width = image.shape[1]\n",
    "    height = patchsize[0]\n",
    "    width = patchsize[1]\n",
    "    ver_margin = margin[0]\n",
    "    hor_margin = margin[1]\n",
    "    maxt = img_height - ver_margin - height\n",
    "    maxl = img_width - hor_margin - width\n",
    "    t = np.random.randint(low = ver_margin, high = maxt)\n",
    "    l = np.random.randint(low = hor_margin, high = maxl)\n",
    "    h = height\n",
    "    w = width\n",
    "    return (t, l, h, w)\n",
    "\n",
    "def bbox2mask(image, margin, patchsize, times):\n",
    "    \"\"\"Generate mask tensor from bbox.\n",
    "    Args:\n",
    "    bbox: configuration tuple, (top, left, height, width)\n",
    "    config: Config should have configuration including IMG_SHAPES,\n",
    "    MAX_DELTA_HEIGHT, MAX_DELTA_WIDTH.\n",
    "    Returns:\n",
    "    tf.Tensor: output with shape [1, H, W, 1]\n",
    "    \"\"\"\n",
    "    bboxs = []\n",
    "    for i in range(times):\n",
    "        bbox = random_bbox(image, margin, patchsize)\n",
    "        bboxs.append(bbox)\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        mask = np.zeros((height, width), np.float32)\n",
    "        for bbox in bboxs:\n",
    "            h = int(bbox[2] * 0.1) + np.random.randint(int(bbox[2] * 0.2 + 1))\n",
    "            w = int(bbox[3] * 0.1) + np.random.randint(int(bbox[3] * 0.2) + 1)\n",
    "            image[(bbox[0] + h) : (bbox[0] + bbox[2] - h), (bbox[1] + w) : (bbox[1] + bbox[3] - w)] = 1.\n",
    "#             return image.reshape((1, ) + image.shape).astype(np.float32)\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),transforms.RandomCrop(240),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Resize(128)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
